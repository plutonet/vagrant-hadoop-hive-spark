- Installare Docker (oppure in alternativa Virtualbox)

- Installare Vagrant

- Lanciare da terminale il comando :
  vagrant up --provider=docker

- Collegarsi alla macchina utilizzando
  host : localhost
  port : 2222
  user : root
  private-key : .../vagrant-hadoop-hive-spark/resources/custom/key
  
- tutto il contenuto della macchina virtuale alla cartella /vagrant/ è sincronizzato con .../vagrant-hadoop-hive-spark/

- gli script si trovano in /vagrant/python_script
  lanciare :
    hive -e 'create table rsm;'        #crea la tabella rsm in hive
	spark-submit service_impl.py       #esegue uno script di test del pattern
	python3.7 test_hdfs.py             #esegue uno script di test hdfs


------------------------------------

Se compare l'errore :

Temporary failure resolving 'archive.ubuntu.com'
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/xenial/InRelease  Temporary failure resolving 'archive.ubuntu.com'

probabilmente c'è un problema di proxy

lanciare :
  sudo vim /etc/resolv.conf

ed sostituire nameserver con 
  nameserver 8.8.8.8

---------------------------

per riavviare i servizi:

set password :

passwd root
vi /etc/ssh/sshd_config
  PermitRootLogin yes


cd /usr/local/spark-2.3.0-bin-hadoop2.7/sbin/
./stop-all.sh
./start-all.sh

cd $HIVE_HOME
hive --service metastore &

---------------------------
Setting Sqoop

export TEZ_CONF_DIR/usr/local/tez/conf
export TEZ_JARS=/usr/local/tez/*:/usr/local/tez/lib/*
export HADOOP_CLASSPATH=/vagrant/python_script/jar/commons-collections4-4.4.jar:/vagrant/python_script/jar/ojdbc8.jar
export HADOOP_CLASSPATH=$TEZ_CONF_DIR:$TEZ_JARS:$HADOOP_CLASSPATH

sqoop import --connect jdbc:oracle:thin:@10.64.20.10:1521/dssdbsvi --username geodss_adt  --password AnAsOracledbSvilTgt --query 'SELECT * FROM GEODSS_ADT.DM_INDICATORI_RIF where $CONDITIONS' --delete-target-dir --target-dir hdfs://node1:8020/demo/test/202303 -m 1
